{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use this notebook to test if using CUDA for GPU support.\n",
    "\n",
    "- Example from: https://saturncloud.io/blog/how-to-check-whether-your-code-is-running-on-the-gpu-or-cpu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If youâ€™re using Python and the PyTorch library, you can check whether your code is running on the GPU by using the torch.cuda.is_available() function. This function returns True if a GPU is available and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that your PyTorch code is running on the GPU, you can use the .to() method to move your tensors to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2346,  0.0292,  1.3946,  1.2452,  0.3170,  0.5137,  0.4940,  0.7159,\n",
      "          0.0169, -2.0927],\n",
      "        [-0.4897, -0.7705,  0.7324,  0.3636, -1.4395, -1.2685,  0.9704,  0.1677,\n",
      "          1.2273,  1.3467],\n",
      "        [ 1.9913, -1.4567,  0.2522,  1.7178,  0.6392, -1.7331, -1.3931,  0.7719,\n",
      "         -0.6884, -0.4904],\n",
      "        [-1.5292, -0.2245,  0.1127,  0.4653,  1.1562, -1.2319, -0.4495, -2.1411,\n",
      "          0.2744, -0.2808],\n",
      "        [ 0.3285,  1.1631, -0.9561,  0.0807,  0.1542, -1.4276, -0.7096,  0.0696,\n",
      "          0.7939,  0.7844],\n",
      "        [-0.6216,  0.9098, -1.5618,  0.8892,  1.9879, -0.0685,  0.1270,  0.9557,\n",
      "          0.4280,  0.9314],\n",
      "        [-0.1360, -0.9171, -1.2498,  0.6747,  1.0188, -0.9437, -0.1756,  1.0636,\n",
      "          0.1559,  1.6309],\n",
      "        [ 0.7029, -0.9787,  0.1332,  2.1583,  0.2506,  0.2423,  1.3892,  0.1078,\n",
      "         -0.4498,  0.4735],\n",
      "        [-1.0030,  0.9122,  0.1750,  0.2080,  1.1771, -0.6336,  1.1113,  0.3534,\n",
      "         -0.3276,  0.5937],\n",
      "        [ 1.4226, -0.2348, -0.9416, -2.1668,  0.5067, -0.9489,  1.1944, -0.1743,\n",
      "          1.4450, -0.3816]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "x = torch.randn(10, 10).to(device)\n",
    "\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
