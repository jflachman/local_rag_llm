{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain dependencies\n",
    "import streamlit as st\n",
    "import os\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader # Importing PDF loader from Langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # Importing text splitter from Langchain\n",
    "from langchain.embeddings import OpenAIEmbeddings # Importing OpenAI embeddings from Langchain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import Document # Importing Document schema from Langchain\n",
    "from langchain.vectorstores.chroma import Chroma # Importing Chroma vector store from Langchain\n",
    "from dotenv import load_dotenv # Importing dotenv to get API key from .env file\n",
    "from langchain.chat_models import ChatOpenAI # Import OpenAI LLM\n",
    "import os # Importing os module for operating system functionalities\n",
    "import shutil # Importing shutil module for high-level file operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Page Configuration for Streamlit\n",
    "st.set_page_config(\n",
    "    page_title = \"Local RAG llm\",\n",
    "    layout='wide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Citation: Kalota, F. A Primer on\n",
      "Generative Artificial Intelligence.\n",
      "Educ. Sci. 2024 ,14, 172. https://\n",
      "doi.org/10.3390/educsci14020172\n",
      "Academic Editors: Gary K. W. Wong\n",
      "and Ho-Yin Cheung\n",
      "Received: 6 August 2023\n",
      "Revised: 20 January 2024\n",
      "Accepted: 24 January 2024\n",
      "Published: 7 February 2024\n",
      "Copyright: ©2024 by the author.\n",
      "Licensee MDPI, Basel, Switzerland.\n",
      "This article is an open access article\n",
      "distributed under the terms and\n",
      "conditions of the Creative Commons\n",
      "Attribution (CC BY) license (https://\n",
      "creativecommons.org/licenses/by/\n",
      "4.0/).\n",
      "education \n",
      "sciences \n",
      "Review\n",
      "A Primer on Generative Artificial Intelligence\n",
      "Faisal Kalota\n",
      "Center for Information and Communication Sciences, Ball State University, Muncie, IN 47306, USA;\n",
      "faisal.kalota@bsu.edu\n",
      "Abstract: Many educators and professionals in different industries may need to become more familiar\n",
      "with the basic concepts of artificial intelligence (AI) and generative artificial intelligence (Gen-AI).\n",
      "Therefore, this paper aims to introduce some of the basic concepts of AI and Gen-AI. The approach\n",
      "of this explanatory paper is first to introduce some of the underlying concepts, such as artificial\n",
      "intelligence, machine learning, deep learning, artificial neural networks, and large language models\n",
      "(LLMs), that would allow the reader to better understand generative AI. The paper also discusses\n",
      "some of the applications and implications of generative AI on businesses and education, followed by\n",
      "the current challenges associated with generative AI.\n",
      "Keywords: artificial intelligence; AI; generative artificial intelligence; generative AI; GAI; GenAI;\n",
      "Gen-AI; ChatGPT; LLM; GPT; AI businesses; AI education; AI ethics; AI security\n",
      "1. Introduction\n",
      "As the world experiences the Fourth Industrial Revolution, also known as Industry\n",
      "4.0, it becomes essential to understand the various technologies relevant to Industry 4.0.\n",
      "These technologies include, but are not limited to, artificial intelligence (AI), blockchains,\n",
      "digital twins, and edge computing. AI has gained much momentum in recent years, and\n",
      "the release of ChatGPT in late 2022 has added to this momentum. Generative AI may\n",
      "play a role in environments such as manufacturing by providing information support and\n",
      "enhancing robotics [ 1]. Many educators may need to become more familiar with some\n",
      "basic concepts and technologies associated with AI and generative AI. Therefore, this paper\n",
      "serves as a primer on generative AI.\n",
      "Simply put, generative AI generates content, which could be text, images, or multime-\n",
      "dia. However, one must understand some of the basic concepts before taking a deeper dive\n",
      "into generative AI. Hence, this paper starts with an explanation of AI and the relevant AI\n",
      "tools and techniques, followed by an introduction to generative AI (Gen-AI). Additionally,\n",
      "this paper briefly touches upon some of the applications of Gen-AI, followed by challenges\n",
      "and opportunities associated with Gen-AI and future recommendations.\n",
      "2. Artificial Intelligence\n",
      "We will start our discussion with the meaning of intelligence. There are several defini-\n",
      "tions and attributes of intelligence. Britannica defines intelligence as the “mental quality\n",
      "that consists of the abilities to learn from experience, adapt to new situations, understand\n",
      "and handle abstract concepts, and use knowledge to manipulate one’s environment” [ 2].\n",
      "While this may not be the absolute agreed-upon definition of intelligence, the definition\n",
      "mentions some critical concepts associated with intelligence. Many of the concepts asso-\n",
      "ciated with intelligence also apply to AI; therefore, as we take a deeper dive into AI, we\n",
      "should reflect upon the relevance of this definition to AI.\n",
      "Artificial intelligence (AI) has gained much momentum in recent years due to the\n",
      "advancements in hardware and software technologies. AI has several definitions, and some\n",
      "of them share similar attributes. Some of these definitions are listed as under:\n",
      "Educ. Sci. 2024 ,14, 172. https://doi.org/10.3390/educsci14020172 https://www.mdpi.com/journal/education' metadata={'source': '..\\\\data\\\\A Primer on Generative Artificial Intelligence.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "# Directory to your pdf files:\n",
    "DATA_PATH = \"../data\"\n",
    "def load_documents():\n",
    "  \"\"\"\n",
    "  Load PDF documents from the specified directory using PyPDFDirectoryLoader.\n",
    "  Returns:\n",
    "  List of Document objects: Loaded PDF documents represented as Langchain\n",
    "                                                          Document objects.\n",
    "  \"\"\"\n",
    "  # Initialize PDF loader with specified directory\n",
    "  document_loader = PyPDFDirectoryLoader(DATA_PATH) \n",
    "  # Load PDF documents and return them as a list of Document objects\n",
    "  return document_loader.load() \n",
    "\n",
    "documents = load_documents() # Call the function\n",
    "# Inspect the contents of the first document as well as metadata\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(documents: list[Document]):\n",
    "  \"\"\"\n",
    "  Split the text content of the given list of Document objects into smaller chunks.\n",
    "  Args:\n",
    "    documents (list[Document]): List of Document objects containing text content to split.\n",
    "  Returns:\n",
    "    list[Document]: List of Document objects representing the split text chunks.\n",
    "  \"\"\"\n",
    "  # Initialize text splitter with specified parameters\n",
    "  text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300, # Size of each chunk in characters\n",
    "    chunk_overlap=100, # Overlap between consecutive chunks\n",
    "    length_function=len, # Function to compute the length of the text\n",
    "    add_start_index=True, # Flag to add start index to each chunk\n",
    "  )\n",
    "\n",
    "  # Split documents into smaller chunks using text splitter\n",
    "  chunks = text_splitter.split_documents(documents)\n",
    "  print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "\n",
    "  # Print example of page content and metadata for a chunk\n",
    "  document = chunks[0]\n",
    "  print(document.page_content)\n",
    "  print(document.metadata)\n",
    "\n",
    "  return chunks # Return the list of split text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# service_context=ServiceContext.from_defaults(llm=OpenAI(temperature=0, model=\"gpt-3.5-turbo\", api_key=\"sk-proj-O7P7AxMfq3M13eMHz5ZxT3BlbkFJzngJzu9d4UFdBJlMjp2x\"))\n",
    "# print(service_context.llm.complete(\"Hello!\"))\n",
    "\n",
    "\n",
    "# Path to the directory to save Chroma database\n",
    "CHROMA_PATH = \"chroma\"\n",
    "def save_to_chroma(chunks: list[Document]):\n",
    "  \"\"\"\n",
    "  Save the given list of Document objects to a Chroma database.\n",
    "  Args:\n",
    "  chunks (list[Document]): List of Document objects representing text chunks to save.\n",
    "  Returns:\n",
    "  None\n",
    "  \"\"\"\n",
    "\n",
    "  # Clear out the existing database directory if it exists\n",
    "  if os.path.exists(CHROMA_PATH):\n",
    "    shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "  # Create a new Chroma database from the documents using OpenAI embeddings\n",
    "  db = Chroma.from_documents(\n",
    "    chunks,\n",
    "    OpenAIEmbeddings(),\n",
    "    persist_directory=CHROMA_PATH\n",
    "  )\n",
    "\n",
    "  # Persist the database to disk\n",
    "  db.persist()\n",
    "  print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 48 documents into 687 chunks.\n",
      "Citation: Kalota, F. A Primer on\n",
      "Generative Artificial Intelligence.\n",
      "Educ. Sci. 2024 ,14, 172. https://\n",
      "doi.org/10.3390/educsci14020172\n",
      "Academic Editors: Gary K. W. Wong\n",
      "and Ho-Yin Cheung\n",
      "Received: 6 August 2023\n",
      "Revised: 20 January 2024\n",
      "Accepted: 24 January 2024\n",
      "Published: 7 February 2024\n",
      "{'source': '..\\\\data\\\\A Primer on Generative Artificial Intelligence.pdf', 'page': 0, 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "def generate_data_store():\n",
    "  \"\"\"\n",
    "  Function to generate vector database in chroma from documents.\n",
    "  \"\"\"\n",
    "  documents = load_documents() # Load documents from a source\n",
    "  chunks = split_text(documents) # Split documents into manageable chunks\n",
    "  #save_to_chroma(chunks) # Save the processed data to a data store\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "# Generate the data store\n",
    "generate_data_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    " - -\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find matching results.\n",
      "Without additional context, it is difficult to provide a specific answer to this question. However, some potential negative side effects of traditional medicine could include adverse reactions to herbal ingredients, lack of regulation leading to inconsistent quality and potency of products, and potential interactions with other medications.\n"
     ]
    }
   ],
   "source": [
    "def query_rag(query_text):\n",
    "  \"\"\"\n",
    "  Query a Retrieval-Augmented Generation (RAG) system using Chroma database and OpenAI.\n",
    "  Args:\n",
    "    - query_text (str): The text to query the RAG system with.\n",
    "  Returns:\n",
    "    - formatted_response (str): Formatted response including the generated text and sources.\n",
    "    - response_text (str): The generated response text.\n",
    "  \"\"\"\n",
    "  # YOU MUST - Use same embedding function as before\n",
    "  embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "  # Prepare the database\n",
    "  db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "  \n",
    "  # Retrieving the context from the DB using similarity search\n",
    "  results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "\n",
    "  # Check if there are any matching results or if the relevance score is too low\n",
    "  if len(results) == 0 or results[0][1] < 0.7:\n",
    "    print(f\"Unable to find matching results.\")\n",
    "\n",
    "  # Combine context from matching documents\n",
    "  context_text = \"\\n\\n - -\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    " \n",
    "  # Create prompt template using context and query text\n",
    "  prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "  prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "  \n",
    "  # Initialize OpenAI chat model\n",
    "  model = ChatOpenAI()\n",
    "\n",
    "  # Generate response text based on the prompt\n",
    "  response_text = model.predict(prompt)\n",
    " \n",
    "   # Get sources of the matching documents\n",
    "  sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    " \n",
    "  # Format and return response including generated text and sources\n",
    "  formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "  return formatted_response, response_text\n",
    "\n",
    "# Let's call our function we have defined\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "# and finally, inspect our final response!\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The RAG is working"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
